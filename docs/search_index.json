[
["robust.html", "Chapter 4 Checking for Robustness 4.1 Identifying Analytical Choices 4.2 Identifying Choice Type 4.3 Identifying Analytical Choices 4.4 Identifying Analytical Value 4.5 Choose and justify alternative values for analytical choices 4.6 Test the robustness of results", " Chapter 4 Checking for Robustness Once you have assess and improve the current computational reproducibility of a paper, it is possible to extend the robustness checks presented in the original paper to a much larger number. We use the term robustness check to describe any possible change in a computational choice, both in data analysis and data cleaning, and its subsequent effect on the main estimates of interest. Going back to our diagram that represents the multiple parts of a paper (??), the robustness section is begins at the claim level. For a given claim, there will be several specifications presented in the paper, one of which the authors (or yourself in their abscense) is declared as the main or preferred specification. Identify which display item contains this specificaiton and go back to your reproduction tree for this display item, this will give you a list of all the code files where you can potentially modify a computational choice. Using the example tree discussed in the Assessment stage, we can remove the data files for simplicity and obtain the following: table1.tex (contains preferred specification) |___[code] analysis.R |___[code] final_merge.do |___[code] clean_merged_1_2.do | |___[code] merge_1_2.do | |___[code] clean_raw_1.py | |___[code] clean_raw_2.py |___[code] clean_merged_3_4.do |___[code] merge_3_4.do |___[code] clean_raw_3.py |___[code] clean_raw_4.py This simplified tree gives you a list of potential files where you could test different reasonable specifications. Here we use (CITE SIMONS) definition of reasonable specification which are consist of “(1) sensible tests of the research question, (2) expected to be statistically valid, and (3) not redundant with other specifications in the set” The extension of robustness checks depends on the level of reproducibility. A claim with an associated level 0 or 1 display item cannot have any robustness checks in addition to what is already in the paper. A claim with levels 2-4 might be able to perform some robustness checks regarding the analysis, but not the specific estimates declared in Scoping (it is not computationally reproducible from analysis data or CRA). A claim from level 5 can check the robustness to core of analysis as describe in the paper. Finally a claim associated with levels 6-10 will allow for robustness checks to variable definition and data manipulations. It is important to highlight that the set of feasible robustness checks grows exponentially, as its defined by all the possible combinations of available checks. For example, when checking the robustness to a new variable definition (level 6 and above) reproducers will also have the alternative to test how the main estimate changes under an alternative variable definition and an alternative core analytical choice. Connect to reproduction diagrams trees. Write down analytic choice data base. Identify all possible analytical choices: original and repeated ones. Identify type of choice. Identify choice value. Suggest choice alternative and justify (one line) 4.1 Identifying Analytical Choices As part of the requirements to demonstrate comprehension of the paper and the code researchers conducting the reproduction will be asked to record all the analytical choices identified during the code review process. This is done in two steps: first adding comment lines into the code files where an analytic choice are found, and second, compiling those analytic choices into a standardized data set. In your copy of the replication code, add the comment “# ANALYTICAL CHOICE OF TYPE ____. RECORDED FOR THE FIRST TIME [HERE or IN &quot;FILE_NAME-LINE_NUMBER&quot;]” above each analytical choice detected in the code. Possible types of analytical choices include (but are not limited to): Analytical choices in data cleaning code: Variable definition Data sub-setting Data reshaping (merge, append, long/gather, wide/spread) Others (specify as “processing - other”) Analytical choices in analysis code: Regression function (link function) Key parameters (tuning, tolerance parameters, etc.) Controls Adjustment of standard errors Choice of weights Treatment of missing values Imputations Other (specify as “methods - other”) Once finished, transcribe all the information on analytical choices into a data set. For the source field type “original” whenever the analytical choice is identified for the first time, and file_name-line number every time that the same analytical choice is applied subsequently (for example if a analytic choice is identified for the first time in line 103 and for a second in line 122 their respective values for the source field should be original and code_01.do-L103 respectively). The resulting data base should have the following structure: file_name line_number choice_type choice_value Source code_01.do 73 data sub-setting males original code_01.do 122 variable definition income = wages + capital gains “code_01.do-L103” code_05.R 143 controls age, income, education original … … … … … 4.2 Identifying Choice Type 4.3 Identifying Analytical Choices 4.4 Identifying Analytical Value 4.5 Choose and justify alternative values for analytical choices 4.6 Test the robustness of results Test the robustness of results to alternative (sensible) specifications Identify sensible alternatives to analytical choices. Sample from sensible analytical choices and re-run: report how much do results change as fraction of standard deviations. Jackknife the preferred estimate. Use ML to select among covariates… "]
]
