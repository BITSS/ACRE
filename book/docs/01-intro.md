---
output:
  word_document: default
  html_document: default
---
# Introduction {#intro}

**[ADD ONE PAGER BETWEEN COVER AND INTRO]**

This guidelines are designed to standarized reproduction excercises perfomed in graduate courses or undergraduate thesis. 
The goal is to provide a unifed terminology and standards to assess and improve the computational reproducibility of published research. 
During this excercise, students are ask to report the result of their reproduction in a structure fashion. The work of student will be 
crowdsourced for two purposes. First, the assessments will be aggregated to compute reproducibility rates in economics. Second, the 
improvements to reproducibiliy created by students will be posted to the public, facilitating incremental improvements and critical 
assessment. 


EMPHASIE THAT ASSESSMENT IS OUTPUT SPECIFIC 

## Stages of the exercise

The reproduction exercise is separated into five different stages: scoping, assessment, improvement, robustness and (possible) extensions. 
First students should define the scope of the exercise by declaring a paper and specific output to reproduce. Second, the reproduction materials 
are reviewed and describe in detail. Third, the student can improve the current reproduction materials. Fourth, robustness checks can be carried out
and recorded in a systematic fashion. Finally, students in a research stage, could extend the current paper to new methodologies or data. 
 

                  (1)       (2)         (3)        (4)        (5)
                  scope --> assess --> improve --> robust --> extend
                   ▲         |  |                   ▲
                   |         |  |                   | 
                   |_________|  |___________________|

      Suggested level of effort:
      - Graduate
        research:   5%       10%        5%         10%         70%
      - Graduate
        course:    10%       25%       20%         40%         5%
      - Undergrad.
        thesis:    10%       30%       40%         20%         0%

Figure 1 depicts the connection between the five stages of a reproduction exercise. 
The three main populations that are likely to work with this framework are: graduate students (and researchers) doing research, 
graduate students in a class, and undergraduate students in a thesis project. These three groups will
differ in the amount of time and focus that will place on each stage. Figure 1
suggest some possible time allocation for each category.  

The process described in Figure 1 need not be cronologically linear. Students can realize that the scope of their reproduction is too ambitious and then switch to a less intensive reproduction. Also later in the excercise, students could begin to test different specification for robustness while assessing the current reproduciblity. 

## Recording the results of the exercise

Students will be ask to record the results of their reproduction as they make progress through different stages. After the [scoping stage](#scoping), they will be ask to complete [a survey](https://berkeley.qualtrics.com/jfe/form/SV_8hLHNI6LGSYchEN) that records paper of choice and specific outputs to reproduce. As part of this step students are ask to write a brief (max two page) summary of the paper of choice. In the [assessment stage](#assessment), reproducers should inspect all the reproduction materials (raw data, analysis data and code), draw diagrams that connect the output-to-reproduce with all its inputs, and score the level of reproducibility. All this information will be recorded in a [standarized spreadsheet](ADD LINK). In the next stage, student can record any specific [improvements](#improvements) report any potential increase in the reported level of reproducibility in a second short survery. Finally, in the [robustness stage](#robust) student will record any analytical choice and possible variations of it. 

## Outputs of this excercise  
 -  One-page introduction describing why you chose this paper
 -  Two-page summary of paper
 -  2 Completed surveys:  
       - i  - General information about the paper and specific
      information about output to reproduce.  
       - ii - Assessment of how (computationally) reproducible is the paper; description of improvements to its reproducibility; record of all the analytical choices identified in the exercise.
 -  ACRE report card with all the improvements that were created by the researcher reproducing the paper. The list of improvements will be made public and original authors will receive a copy of the report card. The option of anonymity will be provided to the researchers reproducing the paper.     

 - New Readme file (autogenerated).
 - Data with all analytical choices identified.
 - ?? Narrated description of improvements to original CR of the paper, assessment of robustness of results. Lessons from the exercise and possible future extensions.
